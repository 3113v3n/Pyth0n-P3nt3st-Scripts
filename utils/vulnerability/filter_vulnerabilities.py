import re
from ..shared import VAConfigs


class FilterVulnerabilities(VAConfigs):
    """Filters vulnerabilities depending on scanner used"""

    def __init__(self):
        self.scanner = None

    def update_scanner(self, scanner):
        self.scanner = scanner

    @staticmethod
    def _compile_regex(pattern):
        return re.compile(pattern)

    def filter_vulnerabilities(self, vulnerabilities, filter_param):
        """TODO: Filter vulnerabilities depending on the scanner used"""

        def matches_pattern(column, pattern):
            result = vulnerabilities[column].notna() & vulnerabilities[column].str.contains(pattern, regex=True)
            print(f"Column '{column}', Pattern '{pattern}', Sample: '{vulnerabilities[column].iloc[0]}' -> {result.sum()} matches")
            return result
        # Filter Strings
        PATTERNS = {
            "ssl": self._compile_regex(self.SSL_FILTER_STRINGS),
            "software": self._compile_regex(self.UPGRADE_FILTER_STRINGS),
            "reboot": self._compile_regex(self.REBOOT_FILTER_STRINGS),
            "patch": self._compile_regex(self.PATCH_FILTER_STRINGS),
            "rdp": self._compile_regex(self.RDP_FILTER_STRINGS),
            "web": self._compile_regex(self.WEB_FILTER_STRINGS),
            "web_avoid": self._compile_regex(self.WEB_IGNORE_FILTER),
            "ignore_common": self._compile_regex(self.UNIVERSAL_IGNORE_FILTER)
        }
        column_ = self.COLUMNS[self.scanner]  # COLUMNS['nessus']
        FILTERS = {
            "ssl_condition": {
                'nessus': lambda: ~(
                    matches_pattern(column_.get('solution'), PATTERNS['patch']) |
                    matches_pattern(column_.get('solution'),
                                    PATTERNS['software'])
                ) & matches_pattern(column_.get('title'), PATTERNS['ssl']),
                'rapid': lambda: (
                    matches_pattern(column_.get('title'), PATTERNS['ssl']) |
                    matches_pattern(column_.get('solution'), PATTERNS['ssl'])
                ) & ~(
                    matches_pattern(column_.get('solution'), PATTERNS['ignore_common']) |
                    matches_pattern(column_.get('solution'), PATTERNS['patch']) |
                    matches_pattern(column_.get('solution'),
                                    PATTERNS['software'])
                )
            },
            "missing_patch_condition": {
                'nessus': lambda: matches_pattern(column_.get('solution'), PATTERNS['patch']),
                'rapid': lambda: (
                    matches_pattern(column_.get('solution'), PATTERNS['patch'])&
                    ~matches_pattern(column_.get("solution"),PATTERNS['software'])
                    )
            },
            "unsupported_software_condition": {
                'nessus': lambda: (
                    matches_pattern(column_.get('solution'),
                                    self.regex_word("Upgrade", second_term="Update")) |
                    matches_pattern(column_.get('title'), PATTERNS['software']) |
                    matches_pattern(column_.get('description'), PATTERNS['software']) |
                    matches_pattern(column_.get('solution'),
                                    PATTERNS['software'])&
                    ~matches_pattern(column_.get('solution'), PATTERNS['patch'])
                ),
                'rapid': lambda: (
                    matches_pattern(column_.get('solution'), self.regex_word("Upgrade", second_term="Update")) |
                    matches_pattern(column_.get('title'),
                                    PATTERNS['software'])&
                    ~matches_pattern(column_.get('solution'), PATTERNS['patch'])
                )
            },
            "reboot_condition": {
                'any': lambda: (
                    matches_pattern(column_.get('description'), PATTERNS['reboot']) |
                    matches_pattern(column_.get('solution'),
                                    PATTERNS['reboot'])
                ) & ~(
                    matches_pattern(column_.get('solution'), PATTERNS['patch']) |
                    matches_pattern(column_.get('solution'),
                                    PATTERNS['software'])
                )
            },
            # Simple pattern matches
            **{key: {'any': lambda p=pattern:
                     matches_pattern(column_.get('title'),
                                     self.regex_word(p))
                     }
               for key, pattern in [
                ('kaspersky_condition', 'Kaspersky'),
                ('insecure_condition', 'Insecure Windows Service'),
                ('winverify_condition', 'WinVerifyTrust'),
                ('unquoted_condition', 'Unquoted Service Path'),
                ('smb_condition', 'SMB'),
                ('speculative_condition', 'Windows Speculative'),
                ('AD_condition', 'AD Starter')
            ]},
            "defender_condition": {
                'any': lambda: matches_pattern(
                    column_.get('synopsis'),
                    self.regex_word('antimalware'))
            },
            "rdp_condition": {
                'any': lambda: matches_pattern(column_.get('title'), PATTERNS['rdp'])
            },
            "telnet_condition": {
                'any': lambda: matches_pattern(
                    column_.get('title'), self.regex_word('Telnet Server')
                )
            },

            "rce_condition": {
                'any': lambda: matches_pattern(
                    column_.get('description'),
                    self.regex_word('remote code execution')
                )
            },
            "compliance_condition": {'nessus': lambda: (
                matches_pattern(column_.get('risk'), self.regex_word('FAILED')) &
                matches_pattern(
                    column_.get('synopsis'),
                    self.regex_word('Compliance checks'))
            ),
                'rapid': lambda: matches_pattern(
                    column_.get('pci_status'), self.regex_word('Fail'))
            },
            "ssh_condition": {
                'nessus': lambda: (
                    matches_pattern(column_.get('synopsis'),
                                    self.regex_word('SSH server')) &
                    ~matches_pattern(column_.get('solution'),
                                     PATTERNS['ignore_common'])
                ),
                'rapid': lambda: (
                    matches_pattern(
                        column_.get('service'),
                        self.regex_word('SSH')
                    ) &
                    ~matches_pattern(
                        column_.get('solution'),
                        PATTERNS['ignore_common']
                    )
                ) | matches_pattern(column_.get('title'),
                                    self.regex_word('SSH Server'))
            },

            "information_condition": {
                'any': lambda: (
                    matches_pattern(
                        column_.get('title'),
                        self.regex_word('Information Disclosure')) &
                    ~(matches_pattern(
                        column_.get('solution'), PATTERNS['software']) |
                        matches_pattern(
                        column_.get('solution'), PATTERNS['patch'])
                      )
                )
            },
            "database_condition": {
                'any': lambda: (
                    matches_pattern(column_.get('title'),
                                    self.regex_word('Database')) &
                    ~matches_pattern(column_.get('solution'),
                                     PATTERNS['ignore_common'])
                )
            },
            "web_condition": {
                'nessus': lambda: (
                    (
                        matches_pattern(column_.get('title'), PATTERNS['web']) |
                        matches_pattern(column_.get('description'), PATTERNS['web']) |
                        matches_pattern(column_.get(
                            'solution'), PATTERNS['web'])
                    ) & ~(
                        matches_pattern(column_.get('title'), PATTERNS['web_avoid']) |
                        matches_pattern(column_.get(
                            'description'), PATTERNS['web_avoid'])
                    ) & ~(
                        matches_pattern(column_.get('solution'), PATTERNS['software']) |
                        matches_pattern(column_.get(
                            'solution'), PATTERNS['patch'])
                    )
                ),
                'rapid': lambda: (
                    ~(
                        matches_pattern(column_.get('title'), PATTERNS['web_avoid']) |
                        matches_pattern(column_.get('solution'), PATTERNS['software']) |
                        matches_pattern(column_.get('solution'),
                                        PATTERNS['patch'])
                    ) & matches_pattern(column_.get('service'), PATTERNS['web'])
                )
            }
        }

        scanner = self.scanner if self.scanner in [
            'nessus', 'rapid'] else 'any'
        if filter_param in FILTERS:
            condition = FILTERS[filter_param].get(
                scanner, FILTERS[filter_param].get('any'))
            if condition:
                return {filter_param: condition()}
        return {}

    @staticmethod
    def loop_through_files(
        file_list: list,
        start_file,
        read_csv: callable,  # reference a callable function
        original_datafile,
        error_text: str,
        get_missing_columns: callable,
        concat_dataframes: callable,
        read_xlsx: callable,
        get_file_extension: callable,
    ):
        """
        Process multiple files and combine their data

        Args:
            file_list: List of files to process
            start_file: Initial file path
            read_csv: Function to read CSV files
            original_datafile: Initial dataframe to compare against
            error_text: Error message for column mismatch
            get_missing_columns: Function to check missing columns
            concat_dataframes: Function to combine dataframes
            read_xlsx: Function to read Excel files
            get_file_extension: Function to get file extension
        """
        all_vulnerabilities = original_datafile
        for file in file_list:
            full_file_path = file["full_path"]

            if full_file_path != start_file:
                try:

                    file_extension = get_file_extension(full_file_path)

                    # Use relevant pandas method depending on file
                    if file_extension.lower() in ["xlsx", "xls"]:
                        new_data = read_xlsx(full_file_path, header=None)
                    elif file_extension.lower() == "csv":
                        new_data = read_csv(full_file_path, header=None)
                    else:
                        raise ValueError(
                            f"Unsupported file extension: {file_extension}"
                        )
                        continue
                    # Check if new data is empty
                    if new_data.empty:
                        print(f"Skipping empty file : {file['filename']}")
                        continue

                    # Ensure columns match
                    if original_datafile.shape[1] != new_data.shape[1]:
                        print(
                            f"New file {file['filename']} has "
                            f"{len(new_data.columns)} columns "
                        )
                        raise ValueError(error_text)

                    # Check if other files have missing columns
                    get_missing_columns(new_data, file["filename"])
                    # Append new data to the original data
                    all_vulnerabilities = concat_dataframes(
                        all_vulnerabilities, new_data
                    )
                except Exception as e:
                    print(f"Error processing file {file['filename']}: {e}")
                    continue

        return all_vulnerabilities

    @staticmethod
    def percentage_null_fields(dataframe):
        # determine percentage accuracy of the data by showing null fields
        for i in dataframe.columns:
            null_rate = dataframe[i].isna().sum() / len(dataframe) * 100
            if null_rate > 0:
                print(f"{i} null rate: {null_rate:.2f}%")

    @staticmethod
    def csv_filter_operations(dataframe, filter_option, operation, **kwargs):
        # Function to combine all the major CSV filters into one for code clarity
        match operation:
            case "notnull":
                return dataframe[filter_option].notna()
            case "contains":
                if "contains_key" in kwargs:
                    # check for any key value pair passed as an  extra argument and uses it as a filter
                    return dataframe[filter_option].str.contains(kwargs["contains_key"])
            case "in":
                if "in_key" in kwargs:
                    return dataframe[filter_option].isin(kwargs["in_key"])
            case _:
                raise ValueError(f"Invalid filter option: {filter_option}")

    @staticmethod
    def regex_word(search_term: str, **kwargs):
        """Performs a regex check against a given term
        :param  search_term: string containg the characters to search for
        :param  kwargs: 
                second_term: second value to search against
                checks for text that has the first term but not the second

        :returns text
        """
        if kwargs.get("second_term"):
            return rf'\b{search_term}\b(?!.*\b{kwargs["second_term"]}\b)'
        return rf"\b{search_term}\b"
